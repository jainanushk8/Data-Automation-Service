name: Auto Data Cleaning Pipeline

on:
  # Trigger when CSV files are pushed to data/raw/
  push:
    paths:
      - 'data/raw/*.csv'
  
  # Manual trigger button in GitHub Actions tab
  workflow_dispatch:

jobs:
  clean-and-process:
    runs-on: ubuntu-latest
    
    steps:
      # Step 1: Checkout the repository
      - name: Checkout Repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0  # Full history for proper git operations

      # Step 2: Set up Python 3.10
      - name: Set up Python 3.10
        uses: actions/setup-python@v5
        with:
          python-version: '3.10'
          cache: 'pip'  # Cache pip dependencies for faster runs

      # Step 3: Install dependencies
      - name: Install Dependencies
        run: |
          python -m pip install --upgrade pip
          pip install pandas numpy openpyxl

      # Step 4: Run the cleaning script
      - name: Run Data Cleaning Script
        run: python process_data.py

      # Step 5: Commit and push cleaned files back to repo
      - name: Commit Cleaned Files
        run: |
          git config --global user.name "Data Pipeline Bot"
          git config --global user.email "actions@github.com"
          git add data/processed/*.csv
          git diff --staged --quiet || git commit -m "ðŸ¤– Auto-cleaned data [$(date +'%Y-%m-%d %H:%M')]"
          git push
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
